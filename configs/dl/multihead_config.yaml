model:
  name: multihead_model_tower

  fusion:
    hidden_dims: [1024, 512, 256]
    dropout: 0.2

  heads: # targets resolved from heads
    subcategory:
      type: classification
      tower_dims: [256, 128, 64]
      dropout: 0.15
      out_dim: 14        # number of subcategory classes
      class_weights: [
        0.6730341911315918,
        0.5076991319656372,
        0.5183828473091125,
        2.605405569076538,
        1.044755220413208,
        0.9416099786758423,
        0.7752261161804199,
        0.6295569539070129,
        0.8485146760940552,
        10.0,
        1.571821689605713,
        1.0157573223114014,
        0.5066832304000854,
        1.6218317747116089]
      loss_weight: 5
    priority:
      type: binary
      out_dim: 1      # number of priority classes
      pos_weight: 1
    avariya:
      type: binary
      out_dim: 1
      pos_weight: 62.16002864047257

features:
  oe_cats:
    path: oe_cat_features.npz
    cardinalities: [23, 881, 6] # S_NAME, REG, SOURCE
    emb_dim: 32
  bin_cats:
    path: bin_cat_features.npz
    input_dim: 17 # 16 sensitive + HAS_TEXT
  times:
    path: time_features.npz
    mlp_dims: [32, 16]
    input_dim: 7
  text:
    path: question_bge_m3.npz
    # mlp_dims: [512, 256]
    input_dim: 1024

training:
  batch_size: 32
  epochs: 30
  lr: 0.0005
  num_workers: 10

  feature_dropout:
    oe_cats: 0.5 
    bin_cats: 0.2
    times: 0.2
    # text: 0.0      # never drop text embeddings
