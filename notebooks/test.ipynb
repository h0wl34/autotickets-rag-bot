{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98552dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "b078ac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = pd.read_csv('./data/processed/cleaned_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "8fd5d0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b61273e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed/lil_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c06584cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'C:\\\\Users\\\\mew\\\\Projects\\\\autotickets-rag-bot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "04b4d916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.models.multihead_model\n",
    "import src.preprocessing.preprocess\n",
    "import src.preprocessing.feature_engineering\n",
    "import src.inference.predictor\n",
    "import src.inference.postprocessor\n",
    "\n",
    "from src.preprocessing.preprocess import Preprocessor\n",
    "from src.preprocessing.feature_engineering import FeatureEngineer\n",
    "from src.inference.predictor import Predictor\n",
    "from src.inference.postprocessor import  Postprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c368a802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.inference.postprocessor' from 'C:\\\\Users\\\\mew\\\\Projects\\\\autotickets-rag-bot\\\\src\\\\inference\\\\postprocessor.py'>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(src.models.multihead_model)\n",
    "reload(src.preprocessing.preprocess)\n",
    "reload(src.preprocessing.feature_engineering)\n",
    "reload(src.inference.predictor)\n",
    "reload(src.inference.postprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "4023d38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open('./configs/inference.yaml', 'r') as f:\n",
    "    cfg = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "82f567d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep = Preprocessor(cfg['preprocessing'])\n",
    "# fe = FeatureEngineer(cfg['preprocessing'])\n",
    "# postp = Postprocessor(cfg['postprocessing'])\n",
    "predictor = Predictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bd7cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "request = {\n",
    "    \"QUESTION\": \"ВСЕ СЛОМАЛОСЬ ВСЕ СЛОМАЛОСЬ ВСЕ СЛОМАЛОСЬ  ВСЕ СЛОМАЛОСЬ ВСЕ СЛОМАЛОСЬ ВСЕ СЛОМАЛОСЬ ВСЕ СЛОМАЛОСЬ ВСЕ СЛОМАЛОСЬ\",\n",
    "    \"S_NAME\": \"CЭД\",\n",
    "    \"REG\": \"Московская Ообласть\",\n",
    "    \"SOURCE\": \"Электронная почта\",\n",
    "    \"OPEN_TIME_\": \"2025-08-24T09:41:00\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "07b42fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_to_request(sample):\n",
    "    return {\n",
    "        \"QUESTION\": sample['QUESTION'],\n",
    "        \"S_NAME\": sample['S_NAME'],\n",
    "        \"REG\": sample['REG'],\n",
    "        \"SOURCE\": sample['SOURCE'],\n",
    "        \"OPEN_TIME_\": sample['OPEN_TIME_']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b97c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avariya                                [Нет]\n",
      "priority                                 [3]\n",
      "subcategory    [Запрос на администрирование]\n",
      "dtype: object \n",
      "\n",
      "AVARIYA                                                       Да\n",
      "PRIORITY                                                       3\n",
      "SUBCATEGORY                                               Авария\n",
      "QUESTION       некорректная работа сервиса, не удается войти ...\n",
      "Name: 399263, dtype: object\n"
     ]
    }
   ],
   "source": [
    "s = df[df['AVARIYA'] == 'Да'].sample().iloc[0]\n",
    "req = sample_to_request(s)\n",
    "\n",
    "print(pd.Series(postpr.process(pr.predict(req))), '\\n')\n",
    "\n",
    "print(s[['AVARIYA', 'PRIORITY', 'SUBCATEGORY', 'QUESTION']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "f2510a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pipelines.inference_pipeline import InferencePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "58059dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = InferencePipeline(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "13265914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.pipelines.inference_pipeline' from 'C:\\\\Users\\\\mew\\\\Projects\\\\autotickets-rag-bot\\\\src\\\\pipelines\\\\inference_pipeline.py'>"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(src.pipelines.inference_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "4e6c6e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned\n",
      "fengeneered\n",
      "feats:{'oe_cats': tensor([[ 20, 644,   3]]), 'bin_cats': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]), 'times': tensor([[ 0.5000, -0.8660, -0.9749, -0.2225,  1.0000, -0.8978, -0.4404]]), 'text': tensor([[ 0.0075, -0.0043,  0.0080,  ..., -0.0096, -0.0095,  0.0291]])}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'QUESTION'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mew\\anaconda3\\envs\\nlp_course\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'QUESTION'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[366]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m sample = df[df[\u001b[33m'\u001b[39m\u001b[33mAVARIYA\u001b[39m\u001b[33m'\u001b[39m] == \u001b[33m'\u001b[39m\u001b[33mДа\u001b[39m\u001b[33m'\u001b[39m].sample()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Projects\\autotickets-rag-bot\\src\\pipelines\\inference_pipeline.py:19\u001b[39m, in \u001b[36mInferencePipeline.run\u001b[39m\u001b[34m(self, sample)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mfengeneered\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mfeats:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeats\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m raw_preds = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mpredicted\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     21\u001b[39m final_preds = \u001b[38;5;28mself\u001b[39m.postproc.process(raw_preds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Projects\\autotickets-rag-bot\\src\\inference\\predictor.py:31\u001b[39m, in \u001b[36mPredictor.predict\u001b[39m\u001b[34m(self, sample)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, sample: \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m     29\u001b[39m     \u001b[38;5;66;03m# sample: {\"QUESTION\": ..., \"TITLE\": ..., \"S_NAME\": ..., ...}\u001b[39;00m\n\u001b[32m     30\u001b[39m     df = pd.DataFrame([sample])\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     df = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpreproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m     feats = \u001b[38;5;28mself\u001b[39m.fe.transform(df)\n\u001b[32m     34\u001b[39m     features = {k: v.to(\u001b[38;5;28mself\u001b[39m.device) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m feats.items()}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Projects\\autotickets-rag-bot\\src\\preprocessing\\preprocess.py:82\u001b[39m, in \u001b[36mPreprocessor.transform_dataframe\u001b[39m\u001b[34m(self, df)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Vectorized cleaning for a dataframe.\"\"\"\u001b[39;00m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.text_cols:\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     df[col + \u001b[33m\"\u001b[39m\u001b[33m_clean\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m.apply(\u001b[38;5;28mself\u001b[39m._clean_text)\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mew\\anaconda3\\envs\\nlp_course\\Lib\\site-packages\\pandas\\core\\frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mew\\anaconda3\\envs\\nlp_course\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'QUESTION'"
     ]
    }
   ],
   "source": [
    "sample = df[df['AVARIYA'] == 'Да'].sample()\n",
    "pipeline.run(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "96221c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S_NAME                                                         ЕИР РМУ\n",
       "QUESTION             не работает миграционный учет и регистрация по...\n",
       "ANSWER               Затруднение устранено. В случае нового затрудн...\n",
       "OPEN_TIME_                                         2023-09-23 13:11:37\n",
       "RESOLVE_TIME_                                      2023-09-25 18:27:20\n",
       "CLOSE_TIME_                                        2023-10-02 18:10:31\n",
       "ATC_NEXT_BREACH_                                   2023-09-29 13:00:00\n",
       "TITLE                                      Запрос на администрирование\n",
       "SUBCATEGORY                                Запрос на администрирование\n",
       "REG                             Центральный федеральный округ/г Москва\n",
       "PRIORITY                                                             2\n",
       "AVARIYA                                                            Нет\n",
       "SOURCE                                         Портал самообслуживания\n",
       "ANSWER_clean         Затруднение устранено. В случае нового затрудн...\n",
       "SUBCATEGORY_clean                          Запрос на администрирование\n",
       "QUESTION_clean       не работает миграционный учет и регистрация по...\n",
       "Name: 59, dtype: object"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "a2edfcb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'avariya': ['Нет'],\n",
       " 'priority': ['3'],\n",
       " 'subcategory': array(['Запрос на администрирование'], dtype=object)}"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postpr.process(pr.predict(sample_to_request(sample)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2b5ab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "f5abdb13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'avariya': ['Нет'],\n",
       " 'priority': ['3'],\n",
       " 'subcategory': array(['Запрос на администрирование'], dtype=object)}"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postpr.process(predictor.predict(request))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "0670df00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.inference.postprocessor import Postprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "2a22de55",
   "metadata": {},
   "outputs": [],
   "source": [
    "postpr = Postprocessor(cfg['postprocessing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a162b5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = Postprocessor(cfg['postprocessing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a2bddb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c27e8b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = np.load('../data/features/answer_bge_m3.npy')\n",
    "question = np.load('../data/features/question_bge_m3.npy')\n",
    "title = np.load('../data/features/title_bge_m3.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569aa581",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.arange(len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8139981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('../data/features/answer_bge_m3.npz', features=answer, ids=ids)\n",
    "np.savez_compressed('../data/features/question_bge_m3.npz', features=question, ids=ids)\n",
    "np.savez_compressed('../data/features/title_bge_m3.npz', features=title, ids=ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0090c5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=  pd.read_csv('../data/processed/lil_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9bbe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lil_set = df.sample(100)\n",
    "# lil_set.to_csv('../data/processed/lil_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70b17283",
   "metadata": {},
   "outputs": [],
   "source": [
    "SENSITIVE_PATTERNS = {\n",
    "    \"EMAIL\": r'\\b[A-Za-z0-9._%+-]+@(?:[A-Za-z0-9-]+\\.)+[A-Za-z]{2,}\\b|<\".+?\"@[^>]+>',\n",
    "    \"INN\": r'(?i)инн\\s*\\d{5,12}',\n",
    "    \"PHONE\": r'\\b(?:\\+7|8)?[\\s-]?\\(?\\d{3,4}\\)?[\\s-]?\\d{2,3}[\\s-]?\\d{2}[\\s-]?\\d{2}(?:\\s*\\(доб\\.\\s*\\d+\\))?\\b',\n",
    "    # \"PHONE_EXT\": r'\\b8\\s?\\d{3,4}[\\s-]?\\d{2}[\\s-]?\\d{2}[\\s-]?\\d{2}(?:\\s*\\(доб\\.\\s*\\d+\\))?',\n",
    "    \"VIN\": r'\\b[A-HJ-NPR-Z0-9]{17}\\b',\n",
    "    \"INCEDENT\": r'\\bIM\\d{8-12}\\b',\n",
    "    \"REG_NUMBER\": r'\\b[АВЕКМНОРСТУХ]{1,3}\\d{3,4}[АВЕКМНОРСТУХ]{2}\\b',\n",
    "    \"CASE_NO\": r'\\b(?:[CcSs]D|T)\\d{6,10}\\b',\n",
    "    \"APPEAL_NO\": r'\\b\\d/\\d{9,12}\\b',\n",
    "    \"DOC_NO\": r'№\\s?\\d{1,6}([/\\\\-]?\\d{1,6})?([А-ЯA-Z])?',\n",
    "    \"LONG_ID\": r'\\b\\d{9,}\\b|\\b[a-f0-9]{32,128}\\b|(?:UID|GlndID|GUID)[: ]?[0-9a-fA-F\\-]{16,128}',\n",
    "    \"IP\": r'\\b(?:\\d{1,3}\\.){3}\\d{1,3}\\b',\n",
    "    \"DATE\": r'\\b\\d{2}[./-]\\d{2}[./-]\\d{2,4}(?:\\s?г\\.?)?',\n",
    "    \"FIO\": r'\\b[А-ЯЁ][а-яё]+ [А-ЯЁ]\\.[А-ЯЁ]\\.(?=[\\s,.)/]|$)',\n",
    "    \"USERNAME\": r'\\b[a-zA-Z][a-zA-Z0-9]{3,15}\\d\\b',\n",
    "    \"TOKEN\": r'\\b[a-f0-9]{16,64}\\b|\\b(?=.*[A-Z])(?=.*[a-z])(?=.*\\d)[A-Za-z0-9]{12,64}\\b',\n",
    "    \"URL\": r'https?://[^\\s]+',\n",
    "}\n",
    "\n",
    "def _extract_sensitive_flags(text: str) -> dict:\n",
    "        flags = {f\"HAS_{k}\": 0 for k in SENSITIVE_PATTERNS.keys()}\n",
    "        \n",
    "        if not isinstance(text, str) or text.strip() == \"\" or text == \"[NO_TEXT]\":\n",
    "            flags[\"HAS_TEXT\"] = 0\n",
    "            return flags\n",
    "        \n",
    "        for placeholder in SENSITIVE_PATTERNS.keys():\n",
    "            if placeholder in text:\n",
    "                flags[f\"HAS_{placeholder}\"] = 1\n",
    "        \n",
    "        flags[\"HAS_TEXT\"] = 1\n",
    "        return flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a17465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['QUESTION_clean'][:10].apply(_extract_sensitive_flags).apply(pd.Series).values  df['QUESTION_clean'][:10].apply(_extract_sensitive_flags).apply(pd.Series).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5277bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HAS_EMAIL': 0,\n",
       " 'HAS_INN': 0,\n",
       " 'HAS_PHONE': 0,\n",
       " 'HAS_VIN': 0,\n",
       " 'HAS_INCEDENT': 0,\n",
       " 'HAS_REG_NUMBER': 0,\n",
       " 'HAS_CASE_NO': 0,\n",
       " 'HAS_APPEAL_NO': 0,\n",
       " 'HAS_DOC_NO': 0,\n",
       " 'HAS_LONG_ID': 0,\n",
       " 'HAS_IP': 0,\n",
       " 'HAS_DATE': 0,\n",
       " 'HAS_FIO': 0,\n",
       " 'HAS_USERNAME': 0,\n",
       " 'HAS_TOKEN': 0,\n",
       " 'HAS_URL': 1,\n",
       " 'HAS_TEXT': 1}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_extract_sensitive_flags(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c4ad90a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('c:/Users/mew/Projects/autotickets-rag-bot')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13226c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.preprocessing.feature_engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ddc1296a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing.feature_engineering import FeatureEngineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06858bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55f14893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.preprocessing.feature_engineering' from 'c:\\\\Users\\\\mew\\\\Projects\\\\autotickets-rag-bot\\\\src\\\\preprocessing\\\\feature_engineering.py'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(src.preprocessing.feature_engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59e82eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'cat_encoders' : {\n",
    "        'S_NAME': r'C:\\Users\\mew\\Projects\\autotickets-rag-bot\\models\\vectorizers\\S_NAME_oenc.pkl',\n",
    "        'REG': r'C:\\Users\\mew\\Projects\\autotickets-rag-bot\\models\\vectorizers\\REG_oenc.pkl',\n",
    "        'SOURCE': r'C:\\Users\\mew\\Projects\\autotickets-rag-bot\\models\\vectorizers\\SOURCE_oenc.pkl'\n",
    "        },\n",
    "    'embedding_model_path': './models/embeddings/deepvk_USER-bge-m3',\n",
    "    'sensitive_patterns': {\n",
    "        \"EMAIL\": r'\\b[A-Za-z0-9._%+-]+@(?:[A-Za-z0-9-]+\\.)+[A-Za-z]{2,}\\b|<\".+?\"@[^>]+>',\n",
    "        \"INN\": r'(?i)инн\\s*\\d{5,12}',\n",
    "        \"PHONE\": r'\\b(?:\\+7|8)?[\\s-]?\\(?\\d{3,4}\\)?[\\s-]?\\d{2,3}[\\s-]?\\d{2}[\\s-]?\\d{2}(?:\\s*\\(доб\\.\\s*\\d+\\))?\\b',\n",
    "        # \"PHONE_EXT\": r'\\b8\\s?\\d{3,4}[\\s-]?\\d{2}[\\s-]?\\d{2}[\\s-]?\\d{2}(?:\\s*\\(доб\\.\\s*\\d+\\))?',\n",
    "        \"VIN\": r'\\b[A-HJ-NPR-Z0-9]{17}\\b',\n",
    "        \"INCEDENT\": r'\\bIM\\d{8-12}\\b',\n",
    "        \"REG_NUMBER\": r'\\b[АВЕКМНОРСТУХ]{1,3}\\d{3,4}[АВЕКМНОРСТУХ]{2}\\b',\n",
    "        \"CASE_NO\": r'\\b(?:[CcSs]D|T)\\d{6,10}\\b',\n",
    "        \"APPEAL_NO\": r'\\b\\d/\\d{9,12}\\b',\n",
    "        \"DOC_NO\": r'№\\s?\\d{1,6}([/\\\\-]?\\d{1,6})?([А-ЯA-Z])?',\n",
    "        \"LONG_ID\": r'\\b\\d{9,}\\b|\\b[a-f0-9]{32,128}\\b|(?:UID|GlndID|GUID)[: ]?[0-9a-fA-F\\-]{16,128}',\n",
    "        \"IP\": r'\\b(?:\\d{1,3}\\.){3}\\d{1,3}\\b',\n",
    "        \"DATE\": r'\\b\\d{2}[./-]\\d{2}[./-]\\d{2,4}(?:\\s?г\\.?)?',\n",
    "        \"FIO\": r'\\b[А-ЯЁ][а-яё]+ [А-ЯЁ]\\.[А-ЯЁ]\\.(?=[\\s,.)/]|$)',\n",
    "        \"USERNAME\": r'\\b[a-zA-Z][a-zA-Z0-9]{3,15}\\d\\b',\n",
    "        \"TOKEN\": r'\\b[a-f0-9]{16,64}\\b|\\b(?=.*[A-Z])(?=.*[a-z])(?=.*\\d)[A-Za-z0-9]{12,64}\\b',\n",
    "        \"URL\": r'https?://[^\\s]+',\n",
    "    },\n",
    "    'categorical': ['S_NAME', 'REG', 'SOURCE'],\n",
    "    'time': ['OPEN_TIME_'],\n",
    "    'text_col': 'QUESTION_clean'\n",
    "}\n",
    "fe = FeatureEngineer(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15c104c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Добрый день документ не доходит до ДЧ для пере...\n",
       "1    Регистрация ЗНИ СЭД [USERNAME] Прошу Вас зарег...\n",
       "2                                            [NO TEXT]\n",
       "3    ПЕРЕВЕСТИ СТАТУС ЗАЯВЛЕНИЯ ИДЕНТИФИКАТОР [LONG...\n",
       "4    При сведении дублей высвечивается ошибка: \"про...\n",
       "5                                            [NO TEXT]\n",
       "6    В подсистеме КНД по результатам проведенных пр...\n",
       "7    Здравствуйте. Прошу Вас предоставить доступ в ...\n",
       "8              заявка на предоставление доступа к СООП\n",
       "9    здравствуйте, ЭПТС не подгружает , выдает \"сер...\n",
       "Name: QUESTION_clean, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:10]['QUESTION_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "918f7818",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = fe.transform(df[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dbe010f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'oe_cats': tensor([[ 16, 504,   0],\n",
       "         [ 16, 783,   4],\n",
       "         [ 16, 112,   0]]),\n",
       " 'bin_cats': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]),\n",
       " 'times': tensor([[-0.5000, -0.8660, -0.7818,  0.6235,  1.0000, -0.1012, -0.9949],\n",
       "         [-0.9659, -0.2588,  0.0000,  1.0000,  0.0000, -0.9378,  0.3473],\n",
       "         [-0.8660, -0.5000,  0.9749, -0.2225,  0.0000, -0.5713,  0.8208]]),\n",
       " 'text': tensor([[-0.0239,  0.0296, -0.0763,  ...,  0.0003, -0.0227,  0.0105],\n",
       "         [-0.0498,  0.0068, -0.0506,  ..., -0.0218,  0.0285,  0.0032],\n",
       "         [-0.0301,  0.0220, -0.0478,  ..., -0.0008, -0.0226,  0.0088]])}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6033a8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open('./configs/dl/multihead_config.yaml', \"r\", encoding='utf-8') as f:\n",
    "    model_cfg = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "904de2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.models.multihead_model as mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "abc67453",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.multihead_model import MultiHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "77632d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_config = model_cfg['model']['features']\n",
    "heads_config = model_cfg['model']['heads']\n",
    "model = MultiHeadModel(feats_config, heads_config, model_cfg['model']['hidden_dims'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a4dbf578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiHeadModel(\n",
       "  (cat_embeddings): ModuleList(\n",
       "    (0): Embedding(24, 16)\n",
       "    (1): Embedding(882, 16)\n",
       "    (2): Embedding(7, 16)\n",
       "  )\n",
       "  (time_mlp): Sequential(\n",
       "    (0): Linear(in_features=7, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (text_mlp): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (fusion_mlp): Sequential(\n",
       "    (0): Linear(in_features=209, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (heads): ModuleDict(\n",
       "    (subcategory): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.15, inplace=False)\n",
       "      (3): Linear(in_features=128, out_features=15, bias=True)\n",
       "    )\n",
       "    (priority): Linear(in_features=128, out_features=1, bias=True)\n",
       "    (avariya): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fbd24221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subcategory': tensor([[ 0.0555, -0.0852,  0.0115, -0.3029, -0.1179,  0.0461, -0.0241,  0.0957,\n",
       "           0.0606, -0.0438, -0.0775, -0.0158,  0.1365,  0.0372, -0.0626],\n",
       "         [ 0.0190, -0.0616,  0.0340, -0.2869, -0.0789, -0.0167,  0.0176,  0.1115,\n",
       "           0.2008, -0.0154, -0.0616, -0.0417,  0.1130,  0.0302,  0.0624],\n",
       "         [ 0.0521,  0.0035, -0.0691, -0.2518, -0.1109,  0.0600,  0.0074,  0.1462,\n",
       "           0.0234, -0.0438, -0.0149, -0.0364,  0.1406,  0.0832,  0.0147]],\n",
       "        grad_fn=<SqueezeBackward1>),\n",
       " 'priority': tensor([-0.0660, -0.0810, -0.0322], grad_fn=<SqueezeBackward1>),\n",
       " 'avariya': tensor([0.0758, 0.0536, 0.0037], grad_fn=<SqueezeBackward1>)}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "398f285e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load(\"../data/features/cat_features.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cac0927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "862\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for i in range(a[\"features\"].shape[1]):\n",
    "    print(len(np.unique(a[\"features\"][:, i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a22205db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_directml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3db8a05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from src.data_loader import load_features\n",
    "from src.trainers import train_on_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.model_utils import load_model_bundle\n",
    "from src.data_loader import load_split, load_features, load_target\n",
    "from src.config import MODELS_DIR, TARGETS\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import joblib\n",
    "from sklearn.metrics import classification_report\n",
    "from src.config import DEFAULT_FEATURES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5f2d76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfn = np.load(\"../data/features/question_tfidf.npz\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0f000e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(918476, 8000)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfn['features'].item().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c736303a",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 123332 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m x_cat = load_features([\u001b[33m'\u001b[39m\u001b[33mcat_features.npz\u001b[39m\u001b[33m'\u001b[39m], output_format=\u001b[33m\"\u001b[39m\u001b[33mdense\u001b[39m\u001b[33m\"\u001b[39m)[train_split]\n\u001b[32m      8\u001b[39m x_time = load_features([\u001b[33m'\u001b[39m\u001b[33mtime_features.npz\u001b[39m\u001b[33m'\u001b[39m], output_format=\u001b[33m\"\u001b[39m\u001b[33mdense\u001b[39m\u001b[33m\"\u001b[39m)[train_split]\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m x_tfidf = \u001b[43mload_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mquestion_tfidf.npz\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_format\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdense\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_split\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[31mIndexError\u001b[39m: index 123332 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "features = DEFAULT_FEATURES\n",
    "target_col = TARGETS[\"subcategory\"]\n",
    "\n",
    "train_split = load_split(\"train\")\n",
    "val_split = load_split(\"val\")\n",
    "\n",
    "x_cat = load_features(['cat_features.npz'], output_format=\"dense\")[train_split]\n",
    "x_time = load_features(['time_features.npz'], output_format=\"dense\")[train_split]\n",
    "x_tfidf = load_features(['question_tfidf.npz'], output_format=\"dense\")[train_split]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
