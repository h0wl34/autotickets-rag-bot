{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6074cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1690196b",
   "metadata": {},
   "source": [
    "some duplicates removal (ignore and dont use)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b67361c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_answer_emb = np.load(\"../data/features/answer_bge_m3.npz\")\n",
    "d_question_emb = np.load(\"../data/features/question_bge_m3.npz\")\n",
    "d_title_emb = np.load(\"../data/features/title_bge_m3.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd23b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_emb = d_answer_emb['features']\n",
    "answer_ids = d_answer_emb['ids']\n",
    "\n",
    "question_emb = d_question_emb['features']\n",
    "question_ids = d_question_emb['ids']\n",
    "\n",
    "title_emb = d_title_emb['features']\n",
    "title_ids = d_title_emb['ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c15660e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_idx = np.load(\"../data/processed/duplicate_idx.npy\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "56e04b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218607"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(duplicate_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3bd967a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ~np.isin(answer_ids, duplicate_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "398bf18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_emb_clean = answer_emb[mask]\n",
    "question_emb_clean = question_emb[mask]\n",
    "title_emb_clean = title_emb[mask]\n",
    "\n",
    "new_idx = np.arange(len(answer_emb_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e524179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\"../data/features/answer_bge_m3_d.npz\", features=answer_emb_clean, ids=new_idx)\n",
    "np.savez_compressed(\"../data/features/question_bge_m3_d.npz\", features=question_emb_clean, ids=new_idx)\n",
    "np.savez_compressed(\"../data/features/title_bge_m3_d.npz\", features=title_emb_clean, ids=new_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2600b8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87843eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/targets/targets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b5f04f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: SUBCATEGORY_CLEAN_enc, Unique values: 15\n",
      "Column: PRIORITY_enc, Unique values: 2\n",
      "Column: AVARIYA_enc, Unique values: 2\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(f\"Column: {col}, Unique values: {df[col].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5af01d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "le = joblib.load(\"../models/vectorizers/label_encoder_AVARIYA.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a3e2ee83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Авария, Index: 0\n",
      "Class: Доступ к ИСОД, Index: 1\n",
      "Class: Запрос на администрирование, Index: 2\n",
      "Class: Запрос на доработку, Index: 3\n",
      "Class: Запрос статуса, Index: 4\n",
      "Class: Консультация, Index: 5\n",
      "Class: Коррекция данных, Index: 6\n",
      "Class: Настройка ПО и оборудования, Index: 7\n",
      "Class: ОШС, Index: 8\n",
      "Class: Оборудование, Index: 9\n",
      "Class: Программное обеспечение, Index: 10\n",
      "Class: Программное обеспечение. Региональные ПТК, Index: 11\n",
      "Class: Прочее, Index: 12\n",
      "Class: Прочие вопросы, Index: 13\n",
      "Class: СПГУ. Несколько модулей, Index: 14\n"
     ]
    }
   ],
   "source": [
    "le = joblib.load(\"../models/vectorizers/label_encoder_SUBCATEGORY_CLEAN.pkl\")\n",
    "for c in le.classes_:\n",
    "    print(f\"Class: {c}, Index: {le.transform([c])[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedea4c0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "9130360e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['S_NAME', 'QUESTION', 'ANSWER', 'OPEN_TIME_', 'RESOLVE_TIME_',\n",
       "       'CLOSE_TIME_', 'ATC_NEXT_BREACH_', 'TITLE', 'SUBCATEGORY', 'REG',\n",
       "       'PRIORITY', 'AVARIYA', 'SOURCE', 'QUESTION_FULL', 'SUBCATEGORY_CLEAN'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/processed/cleaned_dataset.csv\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705b987f",
   "metadata": {},
   "source": [
    "### Сплит данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fc25eb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Будем стратифицировать по всем таргетам сразу\n",
    "df['stratify_key'] = df['SUBCATEGORY_CLEAN'].astype(str) + '_' + df['PRIORITY'].astype(str) + df['AVARIYA'].astype(str)\n",
    "counts = df['stratify_key'].value_counts()\n",
    "rare_classes = counts[counts < 20].index\n",
    "df['stratify_key'] = df['stratify_key'].replace(rare_classes, 'OTHER')\n",
    "df['stratify_key'].value_counts()\n",
    "\n",
    "all_ids = df.index.values\n",
    "train_val_ids, test_ids = train_test_split(\n",
    "    all_ids,\n",
    "    test_size=0.10,\n",
    "    random_state=42,\n",
    "    stratify=df['stratify_key'],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Subset stratify_key to the train_val_ids\n",
    "train_val_stratify = df.loc[train_val_ids, 'stratify_key']\n",
    "\n",
    "train_ids, val_ids = train_test_split(\n",
    "    train_val_ids,\n",
    "    test_size=0.15,\n",
    "    random_state=42,\n",
    "    stratify=train_val_stratify,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "np.save(\"../data/splits/train.npy\", train_ids)\n",
    "np.save(\"../data/splits/val.npy\", val_ids)\n",
    "np.save(\"../data/splits/test.npy\", test_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acce727",
   "metadata": {},
   "source": [
    "Добавим выборку поменьше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5cdf7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sizes - Train: 535399, Val: 94483, Test: 69987\n",
      "Subsampled sizes - Train: 178466, Val: 31494, Test: 23329\n"
     ]
    }
   ],
   "source": [
    "def subsample_stratified(ids, stratify_column, fraction=1/3, random_state=42):\n",
    "    \"\"\"Subsample while maintaining stratification\"\"\"\n",
    "    if fraction >= 1.0:\n",
    "        return ids\n",
    "    \n",
    "    # Get the stratify values for these IDs\n",
    "    stratify_values = stratify_column.loc[ids]\n",
    "    \n",
    "    # Perform stratified sampling\n",
    "    subsampled_ids, _ = train_test_split(\n",
    "        ids,\n",
    "        train_size=fraction,\n",
    "        random_state=random_state,\n",
    "        stratify=stratify_values,\n",
    "        shuffle=True\n",
    "    )\n",
    "    return subsampled_ids\n",
    "\n",
    "# # Будем стратифицировать по всем таргетам сразу\n",
    "# df['stratify_key'] = df['SUBCATEGORY_CLEAN'].astype(str) + '_' + df['PRIORITY'].astype(str) + df['AVARIYA'].astype(str)\n",
    "# counts = df['stratify_key'].value_counts()\n",
    "# rare_classes = counts[counts < 20].index\n",
    "# df['stratify_key'] = df['stratify_key'].replace(rare_classes, 'OTHER')\n",
    "# df['stratify_key'].value_counts()\n",
    "\n",
    "# train_ids = np.load('../data/splits/train.npy')\n",
    "# val_ids = np.load('../data/splits/val.npy')\n",
    "# test_ids = np.load('../data/splits/test.npy')\n",
    "\n",
    "# Subsample each split\n",
    "train_ids_subsampled = subsample_stratified(train_ids, df['stratify_key'], fraction=1/3)\n",
    "val_ids_subsampled = subsample_stratified(val_ids, df['stratify_key'], fraction=1/3)\n",
    "test_ids_subsampled = subsample_stratified(test_ids, df['stratify_key'], fraction=1/3)\n",
    "\n",
    "print(f\"Original sizes - Train: {len(train_ids)}, Val: {len(val_ids)}, Test: {len(test_ids)}\")\n",
    "print(f\"Subsampled sizes - Train: {len(train_ids_subsampled)}, Val: {len(val_ids_subsampled)}, Test: {len(test_ids_subsampled)}\")\n",
    "\n",
    "np.save(\"../data/splits/train_small.npy\", train_ids_subsampled)\n",
    "np.save(\"../data/splits/val_small.npy\", val_ids_subsampled)\n",
    "np.save(\"../data/splits/test_small.npy\", test_ids_subsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "01e56b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AVARIYA\n",
       "Нет    619859\n",
       "Да      10023\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[train_val_ids]['AVARIYA'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc291ad4",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4331bf05",
   "metadata": {},
   "source": [
    "### Текстовые фичи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1adeaa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-ID\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=8000,  # можно увеличить для точности\n",
    "    ngram_range=(1,2),\n",
    "    min_df=5\n",
    ")\n",
    "\n",
    "# Используем train split чтобы не было утечки\n",
    "tfidf.fit(df.loc[train_ids, 'QUESTION_FULL'])\n",
    "X_question_full = tfidf.transform(df['QUESTION_FULL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7becc85",
   "metadata": {},
   "source": [
    "Эмбеддинги для всех текстовых фич вычислили отдельно на сервере (bge_m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4740fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_sentence_embeddings(df, column, model_path, save_path=None):\n",
    "#     model = SentenceTransformer(model_path)\n",
    "#     sentences = df[column].tolist()\n",
    "#     embeddings = model.encode(sentences, batch_size=64, show_progress_bar=True)\n",
    "    \n",
    "#     if save_path:\n",
    "#         np.savez_compressed(save_path, embeddings)\n",
    "#     return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d86c40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build_sentence_embeddings(df, 'QUESTION_FULL', model_path='../models/embeddings/deepvk_USER-bge-m3', save_path='../data/features/question_bge_m3.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce57b23",
   "metadata": {},
   "source": [
    "### Категориальные фичи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "52f99a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "le = joblib.load('../models/vectorizers/label_encoder_REG.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "47930a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S_NAME     22\n",
       "REG       933\n",
       "SOURCE      5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[cat_cols].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "220feab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_encoders = {}\n",
    "\n",
    "cat_cols = ['S_NAME', 'REG', 'SOURCE']\n",
    "\n",
    "for col in cat_cols:\n",
    "    oe = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "    oe.fit(df.loc[train_ids, [col]]) \n",
    "    df[col + '_enc'] = oe.transform(df[[col]]).flatten()  # Transform and flatten to 1D\n",
    "    ord_encoders[col] = oe\n",
    "\n",
    "X_cat = df[[c + '_enc' for c in cat_cols]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4046d7f1",
   "metadata": {},
   "source": [
    "### Временные фичи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "59d4c801",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['OPEN_TIME_', 'RESOLVE_TIME_', 'CLOSE_TIME_', 'ATC_NEXT_BREACH_']:\n",
    "    df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "# Encoding cyclical features\n",
    "hour = df['OPEN_TIME_'].dt.hour\n",
    "df['hour_sin'] = np.sin(hour * (2. * np.pi / 24.))\n",
    "df['hour_cos'] = np.cos(hour * (2. * np.pi / 24.))\n",
    "\n",
    "day_of_week = df['OPEN_TIME_'].dt.dayofweek\n",
    "df['day_of_week_sin'] = np.sin(day_of_week * (2. * np.pi / 7.))\n",
    "df['day_of_week_cos'] = np.cos(day_of_week * (2. * np.pi / 7.))\n",
    "\n",
    "df['is_weekend'] = (day_of_week >= 5).astype(int)\n",
    "\n",
    "day_of_month = df['OPEN_TIME_'].dt.day\n",
    "df['day_of_month_sin'] = np.sin(day_of_month * (2. * np.pi / 31.))\n",
    "df['day_of_month_cos'] = np.cos(day_of_month * (2. * np.pi / 31.))\n",
    "\n",
    "X_time = df[['day_of_week_sin', 'day_of_week_cos', 'hour_sin', 'hour_cos', 'day_of_month_sin', 'day_of_month_cos', 'is_weekend']].fillna(0).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0335d40",
   "metadata": {},
   "source": [
    "### Таргеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6d269370",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['SUBCATEGORY_CLEAN', 'PRIORITY', 'AVARIYA']\n",
    "targets = df[target_cols]\n",
    "\n",
    "label_encoders = {}\n",
    "\n",
    "for col in target_cols:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df.loc[train_ids, col])\n",
    "    classes = le.classes_\n",
    "    df[f'{col}_processed'] = df[col].apply(lambda x: np.where(classes == x)[0][0] if x in classes else -1)\n",
    "    df[col + '_enc'] = le.transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "y = df[[c + '_enc' for c in target_cols]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e430741",
   "metadata": {},
   "source": [
    "### Сохраняем фичи, таргеты и векторизаторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fa405f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\"../data/features/question_tfidf.npz\", features=X_question_full, ids=df.index.values)\n",
    "np.savez_compressed('../data/features/cat_features.npz', features=X_cat, ids=df.index.values)\n",
    "np.savez_compressed('../data/features/time_features.npz', features=X_time, ids=df.index.values)\n",
    "\n",
    "y.to_csv('../data/targets/targets.csv', index=False)\n",
    "\n",
    "joblib.dump(tfidf, '../models/vectorizers/tfidf_vectorizer.pkl')\n",
    "for col, le in label_encoders.items():\n",
    "    joblib.dump(le, f'../models/vectorizers/label_encoder_{col}.pkl')\n",
    "for col, oe in ord_encoders.items():\n",
    "    joblib.dump(oe, f'../models/vectorizers/ordinal_encoder_{col}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc5bf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "oo = pd.read_csv(\"../data/targets/targets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb13aa9",
   "metadata": {},
   "source": [
    "Сохраним текстовые фичи для получения эмбеддингов позднее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4b7ed392",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_fulls = df['QUESTION_FULL']\n",
    "titles = df['TITLE']\n",
    "anwers = df['ANSWER']\n",
    "\n",
    "# question_fulls.to_csv('../torch_container/data/input/question_texts.csv', index=False)\n",
    "# titles.to_csv('../torch_container/data/input/title_texts.csv', index=False)\n",
    "anwers.to_csv('../torch_container/data/input/answer_texts.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90eb463b",
   "metadata": {},
   "source": [
    "Проиндексируем эмбеддинги:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "653346fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_bge = np.load('../data/features/question_bge_m3.npy')\n",
    "title_bge = np.load('../data/features/title_bge_m3.npy')\n",
    "answer_bge = np.load('../data/features/answer_bge_m3.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dd757ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('../data/features/question_bge_m3.npz', features=question_bge, ids=df.index.values)\n",
    "np.savez('../data/features/title_bge_m3.npz', features=title_bge, ids=df.index.values)\n",
    "np.savez('../data/features/answer_bge_m3.npz', features=answer_bge, ids=df.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d25e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "timef = np.load('../data/features/time_features.npz')\n",
    "catf = np.load('../data/features/cat_features.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "186c8cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(699869, 7)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timef['features'].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
